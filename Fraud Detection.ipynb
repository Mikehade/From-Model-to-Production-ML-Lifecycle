{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn import manifold, datasets\n",
    "\n",
    "from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.feature_selection\\\n",
    "    import VarianceThreshold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, plot_roc_curve, confusion_matrix\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from flask import Flask, flash, redirect, render_template, request\n",
    "import pandas as pd\n",
    "import csv\n",
    "from multiprocessing import Process\n",
    "\n",
    "from os.path import exists\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from tests import feat_sel_col_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main File Exists\n",
      "server running\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:2005/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [30/May/2022 14:54:35] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [30/May/2022 14:54:39] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    #Check files status to know if static and continuous files exist\n",
    "    file_status(\"creditcard_static.csv\", \"creditcard_cont.csv\")\n",
    "    \n",
    "    #create static dataframe by opening static dataset\n",
    "    df_static = wrangle(\"creditcard_static.csv\")\n",
    "    \n",
    "    #create cotinuous dataframe by opening continuous dataset\n",
    "    df_cont = wrangle(\"creditcard_cont.csv\")\n",
    "    \n",
    "    #new_df_cont = feat_sel(df_cont)\n",
    "    #print(new_df_cont.shape)\n",
    "    \n",
    "    #select relevant features in static dataframe\n",
    "    #new_df_static = feat_sel(df_static)\n",
    "    #print(new_df_static.shape)\n",
    "    #max_ite = flask_app(\"creditcard_cont.csv\")\n",
    "    #print(new_df_static.shape)\n",
    "    #print(max_ite)\n",
    "    flask_app('creditcard_cont.csv')\n",
    "    max_inp = int(index)\n",
    "    \n",
    "    for i in range(max_inp):\n",
    "        \n",
    "        #print(new_df_cont.loc[[i]])\n",
    "        \n",
    "        df_static = df_static.append(df_cont.loc[[i]])\n",
    "        print(df_static.shape)\n",
    "        \n",
    "        new_df_static = feat_sel(df_static)\n",
    "        print(new_df_static.shape)\n",
    "        #split static dataset into test and train\n",
    "        x_train, x_test, y_train, y_test = test_train_split(new_df_static)\n",
    "\n",
    "        #perform Logistic Regression\n",
    "        model = modelling(x_train, y_train)    #x_train, x_test, y_train, y_test\n",
    "\n",
    "        #Evaluate model\n",
    "        auc, eva_sco, preds = evaluation(model, x_test, y_test)  #x_train, x_test, y_train, y_test\n",
    "\n",
    "        print(f\"Evaluation Score: {eva_sco}\")\n",
    "        print(f\"AUC: {auc}\")\n",
    "\n",
    "        #plot curve\n",
    "        plot_roc(x_test, y_test, model)\n",
    "\n",
    "        #plot confusion matrix\n",
    "        plot_mat(y_test, preds)\n",
    "\n",
    "        #log in mlflow\n",
    "        #flow_logs()\n",
    "\n",
    "        #loging with mlflow\n",
    "        loggings(x_train, y_train, x_test, y_test, model)\n",
    "\n",
    "        #log in mlflow\n",
    "        flow_logs(eva_sco, auc)\n",
    "\n",
    "        #end loggings\n",
    "        end_log()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def file_status(datapath1, datapath2):\n",
    "    first_file_exists = exists(datapath1)\n",
    "    sec_file_exists = exists(datapath2)\n",
    "    \n",
    "    if first_file_exists == True and sec_file_exists == True:\n",
    "        print(\"Main File Exists\")\n",
    "        \n",
    "    else:\n",
    "\n",
    "        df = pd.read_csv(\"creditcard.csv\")\n",
    "        #create static dataset and save to csv\n",
    "        df_static = df[:(int(len(df) * 0.95))]\n",
    "        \n",
    "        #crate dataset that will be iterated to mimic continuous dataset\n",
    "        df_cont = df[(int(len(df) * 0.95)):]\n",
    "        df_static.to_csv(\"creditcard_static.csv\", index=False)\n",
    "        df_cont.to_csv(\"creditcard_cont.csv\", index=False)\n",
    "        #return df_static, df_cont\n",
    "        \n",
    "        \n",
    "def wrangle(datapath):\n",
    "    #read data\n",
    "    df = pd.read_csv(datapath)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def feat_sel(data):\n",
    "    \"\"\"Feature Variance to reduce features\n",
    "    by select important features with highest variance \"\"\"\n",
    "    \n",
    "    #X = data.iloc[:,0:30]    #select first thirty features for selection of important ones\n",
    "    #y = data.iloc[:,30]   #isolating output feature\n",
    "    \n",
    "    #isolating output features\n",
    "    leng = len(data.columns) - 1\n",
    "    X = data.iloc[:,0:leng] \n",
    "    y = data.iloc[:,leng]   \n",
    "    \n",
    "    \n",
    "    selector = VarianceThreshold(threshold=0.90) #using a threshold of 90 percent\n",
    "    Var = selector.fit_transform(X)\n",
    "\n",
    "    X = data[data.columns[selector.get_support(indices=True)]]\n",
    "    \n",
    "    z = pd.concat([X, y], axis=1)\n",
    "    return z\n",
    "\n",
    "\n",
    "def test_train_split(data):\n",
    "    \n",
    "    #isolating output features\n",
    "    leng = len(data.columns) - 1\n",
    "    X = data.iloc[:,0:leng] \n",
    "    y = data.iloc[:,leng]   \n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y,\n",
    "    test_size=0.2, random_state = 2020)\n",
    "    \n",
    "    #scaling\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    x_train = pd.DataFrame(scaler.fit_transform(x_train))\n",
    "    x_test = pd.DataFrame(scaler.fit_transform(x_test))\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def modelling(x_train, y_train):  #x_train, xtest, y_train, y_test\n",
    "    \n",
    "    model = LogisticRegression(random_state=None, max_iter=400, solver='newton-cg')\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return model   \n",
    "\n",
    "def evaluation(model, x_test, y_test):\n",
    "    \n",
    "    eval_ = (model.score(x_test, y_test) * 100)\n",
    "    preds = (model.predict(x_test) * 100)\n",
    "    auc = roc_auc_score(y_test, preds)\n",
    "    \n",
    "    return auc, eval_, preds\n",
    "    \n",
    "\n",
    "def plot_roc(x_test, y_test, model):\n",
    "    \n",
    "    #roc curve\n",
    "    roc_plot = plot_roc_curve(model, x_test, y_test, name='Model ROC Curve')\n",
    "    plt.savefig(\"Model_ROC_Curve.png\")\n",
    "    \n",
    "    \n",
    "def plot_mat(y_test, y_pred):\n",
    "    \n",
    "    #confusion matrix\n",
    "    mat = confusion_matrix(y_test, y_pred)\n",
    "    axi = sns.heatmap(mat, annot=True, fmt='g')\n",
    "    axi.invert_xaxis()\n",
    "    axi.invert_yaxis()\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.savefig(\"Model_Confusion_Matrix.png\")\n",
    "    \n",
    "def flow_logs(eva_sco, auc):\n",
    "    \n",
    "    mlflow.log_metric(\"Evaluation Score\", eva_sco)\n",
    "    mlflow.log_metric(\"Area under Curve\",auc)\n",
    "    mlflow.log_artifact(\"Model_ROC_Curve.png\")\n",
    "    mlflow.log_artifact(\"Model_Confusion_Matrix.png\")\n",
    "    \n",
    "\n",
    "def loggings(x_train, y_train, x_test, y_test, model):\n",
    "    sci_model = LogisticRegression(random_state=None, max_iter=400, solver='newton-cg')\n",
    "    mlflow.set_experiment(\"Fraud Detection\")\n",
    "    with mlflow.start_run():\n",
    "        #train(sci_model, x_train, y_train)\n",
    "        modelling(x_train, y_train)\n",
    "        #evaluate(sci_model, x_test, y_test)\n",
    "        evaluation(model, x_test, y_test)\n",
    "        mlflow.sklearn.log_model(sci_model, \"log_reg_model\")\n",
    "        print(\"Model run: \", mlflow.active_run().info.run_uuid)\n",
    "    #mlflow.end_run()\n",
    "\n",
    "def end_log():\n",
    "    mlflow.end_run()\n",
    "\n",
    "\n",
    "\n",
    "def flask_app(datapath):\n",
    "    #warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    lists = []\n",
    "    save = []\n",
    "    app = Flask(__name__)\n",
    "    with open(datapath, \"r\") as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            lists.append(row)\n",
    "    #global a\n",
    "    a = \"on\"\n",
    "\n",
    "    @app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
    "    def index():\n",
    "        global index\n",
    "        message = \"Please enter an Index value\"\n",
    "        if request.method == \"GET\":\n",
    "            return render_template(\"index.html\", list=message)  #list=lists[0]\n",
    "\n",
    "        else:\n",
    "            index = request.form.get(\"index\")\n",
    "            try:\n",
    "                int(index)\n",
    "            except:\n",
    "                return render_template(\"index.html\", list=message)\n",
    "\n",
    "\n",
    "            if not index:\n",
    "                return render_template(\"index.html\", list=message)\n",
    "            #elif int(index) > len(lists):\n",
    "                #return render_template(\"index.html\", list=lists[0])\n",
    "            else:\n",
    "                save = lists[int(index)]\n",
    "                #print(save)\n",
    "                return render_template(\"index.html\", list=f\"Learning with first {index} records in continuous dataset\") #list=lists[int(index)]\n",
    "            \n",
    "    #server = Process(target=app.run(port=2005))\n",
    "    if a == \"on\":\n",
    "        print(\"server running\")\n",
    "        server = Process(target=app.run(port=2005))\n",
    "        server.start()\n",
    "    \n",
    "    @app.route(\"/shutdown\", methods=[\"POST\"])\n",
    "    def shutdown():\n",
    "        #server.terminate()\n",
    "        a = \"off\"\n",
    "        if a == \"off\":\n",
    "            server.terminate()\n",
    "        print(a)\n",
    "        return redirect(\"/\")\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    return index\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Hour  21\n",
      "Minute  46\n",
      "Today is  30\n",
      "Mon is  5\n",
      "Year is  2022\n",
      "Last day of month is 31\n"
     ]
    }
   ],
   "source": [
    "import calendar\n",
    "#import datetime\n",
    "from datetime import date\n",
    "from datetime import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    print(\"Done\")\n",
    "    mon_schedule = schedule()\n",
    "    if mon_schedule == True:\n",
    "        main()\n",
    "\n",
    "def schedule():\n",
    "\n",
    "    t = datetime.now()\n",
    "    year = t.year\n",
    "    day = t.day     #stores day\n",
    "    mon = t.month\n",
    "    ho = t.hour\n",
    "    minut = t.minute\n",
    "\n",
    "    last_day_mon = (calendar.monthrange(year, mon)[1])\n",
    "\n",
    "    \n",
    "    print(\"Hour \", ho)\n",
    "    print(\"Minute \", minut)\n",
    "    print(\"Today is \",day)\n",
    "    print(\"Mon is \", mon)\n",
    "    print(\"Year is \", year)\n",
    "    print(\"Last day of month is\", last_day_mon)\n",
    "    \n",
    "    if day == last_day_mon and ho == 9 and minut == 30:  #checks if date is last day of the month at 9:30am\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def status(num):\n",
    "    num = num\n",
    "    return num\n",
    "\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
